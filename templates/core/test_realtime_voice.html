{% extends 'base.html' %}

{% block title %}Realtime Voice Test{% endblock %}

{% block content %}
<!-- Dashboard-style Hero Section -->
<div class="bg-gradient-dark text-white py-5">
    <div class="container">
        <div class="row align-items-center">
            <div class="col-lg-8">
                <div class="d-flex align-items-center mb-3">
                    <div class="bg-gradient-primary rounded-circle p-3 me-3" style="width: 60px; height: 60px; display: flex; align-items: center; justify-content: center;">
                        <i class="fas fa-microphone-alt fs-3"></i>
                    </div>
                    <div>
                        <h1 class="mb-1 fw-bold">Realtime Voice Assistant Test</h1>
                        <p class="mb-0 opacity-75">Speech-to-Speech with OpenAI Realtime API + RAG</p>
                    </div>
                </div>
            </div>
            <div class="col-lg-4 text-lg-end">
                <div class="d-flex flex-wrap gap-2 justify-content-lg-end align-items-center">
                    <!-- Language Selector -->
                    <div class="voice-language-selector me-3">
                        <label class="form-label text-white mb-1 small fw-medium">Language:</label>
                        <select id="language-selector" class="form-select form-select-sm bg-dark text-light border-0" style="border-radius: 8px; width: auto; display: inline-block;">
                            <option value="auto">Auto-detect</option>
                            <option value="en">English</option>
                            <option value="ms">Bahasa Malaysia</option>
                        </select>
                    </div>
                    <a href="{% url 'dashboard' %}" class="btn btn-sm btn-outline-light">
                        <i class="fas fa-arrow-left me-1"></i>Back to Dashboard
                    </a>
                </div>
            </div>
        </div>
        
        <!-- Assistant Info Alert -->
        <div class="alert alert-info glass-effect mt-4">
            <div class="row g-2">
                <div class="col-lg-3 col-md-6">
                    <strong>Assistant:</strong> {{ assistant.business_type.name }} Customer Service
                </div>
                <div class="col-lg-2 col-md-6">
                    <strong>Knowledge:</strong> {{ assistant.knowledge_base.count }} items
                </div>
                <div class="col-lg-2 col-md-6">
                    <strong>Q&A:</strong> {{ assistant.qnas.count }} pairs
                </div>
                <div class="col-lg-3 col-md-6">
                    <strong>API:</strong> OpenAI Realtime API (Server-side)
                </div>
                <div class="col-lg-2 col-md-6">
                    <strong>Language:</strong> <span id="current-language-display">English</span>
                </div>
            </div>
        </div>
    </div>
</div>

<div class="container mt-n3 position-relative" style="z-index: 10;">
    
    <!-- Dashboard-style Status Cards -->
    <div class="row g-4 mb-5">
        <div class="col-lg-4 col-md-6">
            <div class="card-modern h-100">
                <div class="card-body-modern text-center">
                    <div class="bg-gradient-primary rounded-circle mx-auto mb-3 d-flex align-items-center justify-content-center" style="width: 64px; height: 64px;">
                        <div id="connection-status">
                            <i class="fas fa-circle text-white fs-4"></i>
                        </div>
                    </div>
                    <h3 class="fw-bold text-primary-modern mb-1">Connection</h3>
                    <p class="text-muted mb-0" id="connection-text">Initializing...</p>
                    <small class="text-muted">Server WebSocket</small>
                </div>
            </div>
        </div>
        <div class="col-lg-4 col-md-6">
            <div class="card-modern h-100">
                <div class="card-body-modern text-center">
                    <div class="bg-gradient-primary rounded-circle mx-auto mb-3 d-flex align-items-center justify-content-center" style="width: 64px; height: 64px;">
                        <div id="voice-activity">
                            <i class="fas fa-microphone-slash text-white fs-4"></i>
                        </div>
                    </div>
                    <h3 class="fw-bold text-primary-modern mb-1">Voice Activity</h3>
                    <p class="text-muted mb-0" id="voice-text">Ready</p>
                    <small class="text-muted">Speech Detection</small>
                </div>
            </div>
        </div>
        <div class="col-lg-4 col-md-6">
            <div class="card-modern h-100">
                <div class="card-body-modern text-center">
                    <div class="bg-gradient-primary rounded-circle mx-auto mb-3 d-flex align-items-center justify-content-center" style="width: 64px; height: 64px;">
                        <div id="ai-status">
                            <i class="fas fa-robot text-white fs-4"></i>
                        </div>
                    </div>
                    <h3 class="fw-bold text-primary-modern mb-1">AI Response</h3>
                    <p class="text-muted mb-0" id="ai-text">Standby</p>
                    <small class="text-muted">Model Response</small>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Main Content Row -->
    <div class="row g-4 mb-5">
        
        <!-- Voice Control Panel -->
        <div class="col-lg-6">
            <div class="card-modern h-100">
                <div class="card-header-modern">
                    <i class="fas fa-microphone me-2"></i>
                    <span>Voice Control</span>
                </div>
                <div class="card-body-modern text-center">
                    <!-- Main Voice Button -->
                    <div class="voice-control-center mb-4">
                        <div class="voice-button-container position-relative d-inline-block">
                            <!-- Pulse Animation Ring -->
                            <div class="voice-pulse-ring" style="position: absolute; top: -20px; left: -20px; right: -20px; bottom: -20px; border: 3px solid rgba(0,173,181,0.3); border-radius: 50%; animation: pulse 2s infinite;"></div>
                            <div class="voice-pulse-ring-2" style="position: absolute; top: -10px; left: -10px; right: -10px; bottom: -10px; border: 2px solid rgba(0,173,181,0.2); border-radius: 50%; animation: pulse 2s infinite 0.5s;"></div>
                            
                            <button id="voice-btn" class="btn-primary-modern" 
                                    style="width: 140px; height: 140px; border-radius: 50%; border: none; position: relative; z-index: 10;" 
                                    disabled>
                                <i class="fas fa-microphone" style="font-size: 3rem;"></i>
                            </button>
                        </div>
                        <div class="mt-3">
                            <div id="voice-btn-text" class="fw-bold fs-5 text-primary-modern">Initializing...</div>
                            <small class="text-muted">Click to start conversation</small>
                        </div>
                    </div>

                    <!-- Conversation State -->
                    <div id="conversation-state" class="alert alert-secondary mb-4">
                        <div class="d-flex align-items-center justify-content-center">
                            <span id="state-indicator" class="fs-4 me-2">🤖</span>
                            <span id="state-text" class="fw-bold">Getting ready...</span>
                        </div>
                    </div>

                    <!-- Transcription Preview -->
                    <div id="transcription-preview" class="alert alert-info d-none mb-4">
                        <div class="d-flex align-items-center">
                            <span id="preview-icon" class="fs-5 me-2">👤</span>
                            <div>
                                <small class="text-muted d-block">Live Transcription:</small>
                                <span id="preview-text" class="fw-bold"></span>
                                <span id="typing-indicator" class="text-muted">▋</span>
                            </div>
                        </div>
                    </div>

                    <!-- Instructions -->
                    <div class="alert alert-light border">
                        <h6><i class="fas fa-info-circle me-2"></i>How to use:</h6>
                        <ul class="list-unstyled mb-0 small text-start">
                            <li>• Click the microphone button to START conversation</li>
                            <li>• Speak naturally after clicking start</li>
                            <li>• Your speech is transcribed in REAL-TIME using OpenAI Realtime API</li>
                            <li>• See live transcription preview above</li>
                            <li>• Click the stop button to END conversation</li>
                            <li>• Uses your knowledge base for accurate answers</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Conversation History -->
        <div class="col-lg-6">
            <div class="card-modern h-100">
                <div class="card-header-modern d-flex justify-content-between align-items-center">
                    <div class="d-flex align-items-center">
                        <i class="fas fa-comments me-2"></i>
                        <span>Conversation History</span>
                    </div>
                    <button class="btn btn-sm btn-outline-light" onclick="clearConversation()">
                        <i class="fas fa-trash me-1"></i>Clear
                    </button>
                </div>
                <div class="card-body-modern p-0">
                    <div id="conversation-messages" class="p-3" style="height: 400px; overflow-y: auto; background-color: #f8f9fa;">
                        <!-- Welcome Message -->
                        <div class="message assistant mb-3">
                            <div class="d-flex align-items-start">
                                <div class="avatar me-3">
                                    <div class="bg-gradient-primary rounded-circle p-2 d-flex align-items-center justify-content-center" style="width: 40px; height: 40px;">
                                        <i class="fas fa-robot text-white"></i>
                                    </div>
                                </div>
                                <div class="message-content bg-white p-3 rounded shadow-sm">
                                    <div class="d-flex align-items-center mb-2">
                                        <strong class="text-primary-modern">{{ assistant.business_type.name }} Assistant</strong>
                                        <span class="badge bg-primary ms-2">AI</span>
                                    </div>
                                    Hello! I'm your realtime AI assistant. Click the microphone and start speaking - I'll respond instantly using your knowledge base!
                                    <div class="small text-muted mt-2">
                                        <i class="fas fa-clock me-1"></i>Ready to chat
                                        <i class="fas fa-robot ms-2 me-1"></i>AI Assistant
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Modern Toast Notifications -->
<div class="toast-container position-fixed top-0 end-0 p-3" style="z-index: 9999;">
    <div id="notification-toast" class="toast" role="alert">
        <div class="toast-header">
            <i class="fas fa-microphone-alt me-2 text-primary-modern"></i>
            <strong class="me-auto">Voice Assistant</strong>
            <button type="button" class="btn-close" data-bs-dismiss="toast"></button>
        </div>
        <div class="toast-body" id="toast-message">
            <!-- Dynamic message content -->
        </div>
    </div>
</div>

{% endblock %}

{% block extra_css %}
<style>
/* Pulse Animation */
@keyframes pulse {
    0% {
        transform: scale(1);
        opacity: 1;
    }
    100% {
        transform: scale(1.3);
        opacity: 0;
    }
}

.voice-pulse-ring {
    animation: pulse 2s infinite;
}

.voice-pulse-ring-2 {
    animation: pulse 2s infinite 1s;
}

/* Voice Button States */
.voice-main-button {
    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
}

.voice-main-button:hover:not(:disabled) {
    transform: scale(1.05);
}

.voice-main-button:active:not(:disabled) {
    transform: scale(0.98);
}

.voice-main-button:disabled {
    opacity: 0.6;
    cursor: not-allowed;
}

/* Recording Animation */
@keyframes recording-pulse {
    0%, 100% {
        box-shadow: 0 8px 32px rgba(220, 53, 69, 0.3);
        background: linear-gradient(135deg, #dc3545 0%, #c82333 100%);
    }
    50% {
        box-shadow: 0 8px 40px rgba(220, 53, 69, 0.6);
        background: linear-gradient(135deg, #e74c3c 0%, #dc3545 100%);
    }
}

.voice-main-button.recording {
    animation: recording-pulse 1.5s infinite;
}

/* Transcription Preview */
#transcription-preview {
    border-left: 4px solid var(--primary);
    transition: all 0.3s ease;
}

#transcription-preview.fade-in {
    animation: fadeIn 0.3s ease-in;
}

@keyframes fadeIn {
    from { opacity: 0; transform: translateY(-10px); }
    to { opacity: 1; transform: translateY(0); }
}

#typing-indicator {
    animation: blink 1s infinite;
    color: var(--primary);
}

@keyframes blink {
    0%, 50% { opacity: 1; }
    51%, 100% { opacity: 0.3; }
}

/* Message Animations */
.message {
    animation: messageSlideIn 0.5s ease-out;
}

@keyframes messageSlideIn {
    from {
        opacity: 0;
        transform: translateY(20px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

/* Conversation Scrollbar */
#conversation-messages::-webkit-scrollbar {
    width: 6px;
}

#conversation-messages::-webkit-scrollbar-track {
    background: var(--border);
    border-radius: 3px;
}

#conversation-messages::-webkit-scrollbar-thumb {
    background: var(--primary);
    border-radius: 3px;
}

#conversation-messages::-webkit-scrollbar-thumb:hover {
    background: rgba(0, 173, 181, 0.8);
}

/* Responsive Design */
@media (max-width: 768px) {
    .voice-main-button {
        width: 100px !important;
        height: 100px !important;
    }
    
    .voice-main-button i {
        font-size: 2rem !important;
    }
    
    .voice-pulse-ring {
        top: -15px !important;
        left: -15px !important;
        right: -15px !important;
        bottom: -15px !important;
    }
    
    .voice-pulse-ring-2 {
        top: -8px !important;
        left: -8px !important;
        right: -8px !important;
        bottom: -8px !important;
    }
    
    #conversation-messages {
        height: 300px !important;
    }
}
</style>
{% endblock %}

{% block extra_js %}
<script>
// Configuration
const REALTIME_API_BASE = '/api/realtime-test/';
const FUNCTION_CALL_API = '/api/realtime-function-call/';

// Global state
let currentSessionId = null;
let serverWebSocket = null;
let mediaRecorder = null;
let audioStream = null;
let isConnected = false;
let isListening = false;
let isInConversation = false;
let audioEl = null;
let selectedLanguage = 'auto';

// DOM elements
const voiceBtn = document.getElementById('voice-btn');
const voiceBtnText = document.getElementById('voice-btn-text');
const conversationMessages = document.getElementById('conversation-messages');
const languageSelector = document.getElementById('language-selector');
const currentLanguageDisplay = document.getElementById('current-language-display');

// Transcription preview elements
const transcriptionPreview = document.getElementById('transcription-preview');
const previewIcon = document.getElementById('preview-icon');
const previewText = document.getElementById('preview-text');
const typingIndicator = document.getElementById('typing-indicator');

// Conversation state elements
const conversationState = document.getElementById('conversation-state');
const stateIndicator = document.getElementById('state-indicator');
const stateText = document.getElementById('state-text');

// Status indicators
const connectionStatus = document.getElementById('connection-status');
const connectionText = document.getElementById('connection-text');
const voiceActivity = document.getElementById('voice-activity');
const voiceText = document.getElementById('voice-text');
const aiStatus = document.getElementById('ai-status');
const aiText = document.getElementById('ai-text');

// Initialize the application when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    updateDebugInfo('🎬 Realtime Voice AI initializing...');
    updateDebugInfo('⚡ Powered by OpenAI Realtime API');
    
    // Setup language selector
    setupLanguageSelector();
    
    // Start initialization
    setTimeout(() => {
        initializeRealtimeVoice();
    }, 1000);
});

// Setup language selector event listener
function setupLanguageSelector() {
    if (languageSelector) {
        selectedLanguage = languageSelector.value;
        
        languageSelector.addEventListener('change', function() {
            selectedLanguage = this.value;
            const langNames = {
                'auto': 'Auto-detect',
                'en': 'English',
                'ms': 'Bahasa Malaysia'
            };
            const langName = langNames[selectedLanguage] || 'Auto-detect';
            updateDebugInfo(`🌐 Language switched to: ${langName}`);
            
            updateUILanguage(selectedLanguage);
            
            if (currentLanguageDisplay) {
                currentLanguageDisplay.textContent = langName;
            }
            
            if (isConnected && isInConversation) {
                updateDebugInfo('🔄 Restarting session with new language settings...');
                endConversation();
                setTimeout(() => {
                    startConversation();
                }, 1000);
            }
        });
        
        updateDebugInfo(`🌐 Language initialized: ${selectedLanguage === 'en' ? 'English' : selectedLanguage === 'ms' ? 'Bahasa Malaysia' : 'Auto-detect'}`);
    }
}

// Update UI text based on selected language
function updateUILanguage(lang) {
    const texts = {
        'en': {
            listening: 'Listening...',
            speaking: 'AI Speaking...',
            ready: 'Click the button to start',
            startConversation: 'Start Conversation',
            stopConversation: 'Stop Conversation',
            connected: 'Connected - Audio INACTIVE',
            disconnected: 'Disconnected from server'
        },
        'ms': {
            listening: 'Mendengar...',
            speaking: 'AI Bercakap...',
            ready: 'Klik butang untuk mula',
            startConversation: 'Mula Perbualan',
            stopConversation: 'Henti Perbualan',
            connected: 'Disambung - Audio TIDAK AKTIF',
            disconnected: 'Terputus dari pelayan'
        },
        'auto': {
            listening: 'Listening...',
            speaking: 'AI Speaking...',
            ready: 'Click the button to start',
            startConversation: 'Start Conversation',
            stopConversation: 'Stop Conversation',
            connected: 'Connected - Audio INACTIVE',
            disconnected: 'Disconnected from server'
        }
    };
    
    if (!isInConversation && voiceBtnText) {
        voiceBtnText.textContent = texts[lang]?.startConversation || texts['auto'].startConversation;
    }
}

// Initialize realtime voice connection
async function initializeRealtimeVoice() {
    updateDebugInfo('🚀 Starting realtime voice initialization...');
    updateConnectionStatus('connecting', 'Initializing...');
    updateStatus('connection', 'processing');
    
    try {
        updateDebugInfo('🔗 Connecting to Django WebSocket server...');
        await setupServerSideWebSocket();
        
    } catch (error) {
        updateDebugInfo(`❌ Initialization failed: ${error.message}`);
        updateConnectionStatus('error', 'Connection failed');
        updateStatus('connection', 'error');
        showToast('Failed to initialize voice connection: ' + error.message, 'error');
    }
}

// Setup server-side WebSocket connection  
async function setupServerSideWebSocket() {
    updateDebugInfo('🌐 Setting up server-side WebSocket connection...');
    updateConnectionStatus('connecting', 'Connecting to server...');
    updateStatus('connection', 'processing');

    try {
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${protocol}//${window.location.host}/ws/voice/default/`;
        
        updateDebugInfo(`📡 Connecting to ${wsUrl}`);
        serverWebSocket = new WebSocket(wsUrl);
        
        return new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
                reject(new Error('WebSocket connection timeout'));
            }, 10000);
            
            serverWebSocket.onopen = function(event) {
                clearTimeout(timeout);
                updateDebugInfo('✅ Connected to Django WebSocket server');
                isConnected = true;
                enableVoiceButton();
                updateConnectionStatus('connected', 'Connected to server');
                updateStatus('connection', 'ready');
                resolve();
            };
            
            serverWebSocket.onmessage = function(event) {
                const data = JSON.parse(event.data);
                handleServerMessage(data);
            };
            
            serverWebSocket.onclose = function(event) {
                updateDebugInfo('🔌 WebSocket connection closed');
                isConnected = false;
                isInConversation = false;
                updateConnectionStatus('error', 'Disconnected from server');
                voiceBtn.disabled = true;
                voiceBtnText.textContent = 'Disconnected';
            };
            
            serverWebSocket.onerror = function(error) {
                clearTimeout(timeout);
                updateDebugInfo(`❌ WebSocket error: ${error}`);
                updateConnectionStatus('error', 'Connection error');
                reject(error);
            };
        });
        
    } catch (error) {
        updateDebugInfo(`❌ Failed to setup WebSocket: ${error.message}`);
        updateConnectionStatus('error', 'Failed to connect to server');
        updateStatus('connection', 'error');
        throw error;
    }
}

// Handle messages from Django WebSocket server
function handleServerMessage(data) {
    updateDebugInfo(`📨 Server message: ${data.type}`);
    
    switch (data.type) {
        case 'connection_status':
            updateDebugInfo(`🔗 ${data.message}`);
            break;
            
        case 'voice_started':
            updateDebugInfo(`🎤 ${data.message}`);
            currentSessionId = data.session_id;
            startAudioRecording();
            break;
            
        case 'voice_stopped':
            updateDebugInfo(`🔇 ${data.message}`);
            stopAudioRecording();
            clearAudioQueue();
            break;
            
        case 'audio_received':
            updateDebugInfo(`📡 ${data.message}`);
            break;
            
        case 'error':
            updateDebugInfo(`❌ Server error: ${data.message}`);
            showToast(`Server Error: ${data.message}`, 'error');
            break;
            
        case 'ai_audio_delta':
            updateDebugInfo(`🗣️ AI Audio Delta received`);
            if (data.audio) {
                playAudioDelta(data.audio);
            }
            break;
            
        case 'ai_response_text':
            updateDebugInfo(`📝 AI Response: ${data.text}`);
            addMessageToHistory('assistant', data.text, true);
            break;
            
        case 'openai_error':
            updateDebugInfo(`❌ OpenAI Error: ${data.error}`);
            showToast(`OpenAI Error: ${data.error}`, 'error');
            break;
            
        case 'audio_buffer_start':
            startAudioBuffer();
            break;
            
        case 'audio_buffer_complete':
            completeAudioBuffer();
            break;
            
        case 'user_transcript_delta':
            updateDebugInfo(`👤 Transcribing: "${data.delta}"`);
            updateTranscriptionPreview('user', data.delta, false);
            updateStatus('ai', 'processing');
            break;
            
        case 'user_transcript':
            updateDebugInfo(`✅ Transcription complete: "${data.transcript}"`);
            if (data.transcript) {
                addMessageToHistory('user', data.transcript, true);
                clearTranscriptionPreview();
                updateStatus('ai', 'ready');
                showToast(`🎤 Speech transcribed`, 'success');
            }
            break;
            
        case 'user_transcript_error':
            updateDebugInfo(`❌ User transcription failed: ${JSON.stringify(data.error)}`);
            showToast(`Transcription Error: Unable to transcribe speech`, 'error');
            clearTranscriptionPreview();
            break;
            
        default:
            updateDebugInfo(`📝 Unknown message type: ${data.type}`);
            break;
    }
}

// Add message to conversation history with dashboard styling
function addMessageToHistory(role, content, isTranscription = false) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `message ${role} mb-3`;
    
    const cleanContent = content.replace(/^[^:]*:\s*/, '').trim() || content;
    
    const transcriptionBadge = isTranscription ? 
        '<span class="badge bg-info me-2"><i class="fas fa-microphone me-1"></i>Transcribed</span>' : '';
    
    if (role === 'assistant') {
        messageDiv.innerHTML = `
            <div class="d-flex align-items-start">
                <div class="avatar me-3">
                    <div class="bg-gradient-primary rounded-circle p-2 d-flex align-items-center justify-content-center" style="width: 40px; height: 40px;">
                        <i class="fas fa-robot text-white"></i>
                    </div>
                </div>
                <div class="message-content bg-white p-3 rounded shadow-sm" style="max-width: 85%;">
                    <div class="d-flex align-items-center mb-2">
                        <strong class="text-primary-modern">AI Assistant</strong>
                        <span class="badge bg-primary ms-2">AI</span>
                    </div>
                    ${transcriptionBadge}
                    <p class="mb-0">${cleanContent}</p>
                    <div class="small text-muted mt-2">
                        <i class="fas fa-clock me-1"></i>${new Date().toLocaleTimeString()}
                        <i class="fas fa-microphone ms-2 me-1"></i>Voice
                    </div>
                </div>
            </div>
        `;
    } else {
        messageDiv.innerHTML = `
            <div class="d-flex justify-content-end">
                <div class="message-content p-3 rounded shadow-sm" style="background: var(--gradient-primary); color: white; max-width: 85%;">
                    ${transcriptionBadge}
                    <p class="mb-0">${cleanContent}</p>
                    <div class="small mt-2" style="color: rgba(255,255,255,0.8);">
                        <i class="fas fa-clock me-1"></i>${new Date().toLocaleTimeString()}
                        <i class="fas fa-user ms-2 me-1"></i>You
                    </div>
                </div>
                <div class="avatar ms-3">
                    <div class="bg-light rounded-circle p-2 d-flex align-items-center justify-content-center border border-primary" style="width: 40px; height: 40px;">
                        <i class="fas fa-user text-primary"></i>
                    </div>
                </div>
            </div>
        `;
    }
    
    conversationMessages.appendChild(messageDiv);
    conversationMessages.scrollTop = conversationMessages.scrollHeight;
}

// Status update functions
function updateConnectionStatus(status, text) {
    connectionText.textContent = text;
    const icon = connectionStatus.querySelector('i');
    
    icon.className = 'fas fa-circle text-white fs-4';
    
    // Update status card based on connection state
    switch (status) {
        case 'connected':
            icon.className = 'fas fa-check-circle text-white fs-4';
            break;
        case 'connecting':
            icon.className = 'fas fa-spinner fa-spin text-white fs-4';
            break;
        case 'error':
            icon.className = 'fas fa-times-circle text-white fs-4';
            break;
        default:
            icon.className = 'fas fa-circle text-white fs-4';
    }
}

function updateStatus(type, status) {
    let statusEl, textEl;
    
    switch (type) {
        case 'voice':
            statusEl = voiceActivity.querySelector('i');
            textEl = voiceText;
            break;
        case 'ai':
            statusEl = aiStatus.querySelector('i');
            textEl = aiText;
            break;
        default:
            return;
    }
    
    statusEl.className = 'fas text-white fs-4';
    
    switch (status) {
        case 'listening':
            statusEl.classList.add('fa-microphone');
            textEl.textContent = 'Listening';
            break;
        case 'processing':
            statusEl.classList.add('fa-spinner', 'fa-spin');
            textEl.textContent = 'Processing';
            break;
        case 'speaking':
            statusEl.classList.add('fa-volume-up');
            textEl.textContent = 'Speaking';
            break;
        case 'ready':
            statusEl.classList.add('fa-check-circle');
            textEl.textContent = 'Ready';
            break;
        case 'error':
            statusEl.classList.add('fa-exclamation-triangle');
            textEl.textContent = 'Error';
            break;
        default:
            statusEl.classList.add('fa-circle');
            textEl.textContent = 'Standby';
    }
}

function updateDebugInfo(message) {
    console.log(`[${new Date().toLocaleTimeString()}] ${message}`);
}

function enableVoiceButton() {
    voiceBtn.disabled = false;
    voiceBtn.onclick = toggleConversation;
    
    const texts = {
        'en': 'Start Conversation',
        'ms': 'Mula Perbualan'
    };
    voiceBtnText.textContent = texts[selectedLanguage] || texts['en'];
    
    updateConversationState('ready', '🤖', 'Click the button to start');
    updateStatus('connection', 'ready');
    updateConnectionStatus('connected', 'Connected - Audio INACTIVE');
    
    const langName = selectedLanguage === 'en' ? 'English' : 'Bahasa Malaysia';
    showToast(`🎉 Connection established! Voice ready (${langName}).`, 'success');
}

async function toggleConversation() {
    if (!globalAudioContext) {
        try {
            globalAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 24000
            });
            
            if (globalAudioContext.state === 'suspended') {
                await globalAudioContext.resume();
                updateDebugInfo('🔊 Audio context activated by user interaction');
            }
        } catch (error) {
            updateDebugInfo(`❌ Error initializing audio context: ${error.message}`);
        }
    }
    
    if (!isInConversation) {
        startConversation();
    } else {
        endConversation();
    }
}

function startConversation() {
    if (!isConnected || !serverWebSocket || serverWebSocket.readyState !== WebSocket.OPEN) {
        const errorText = selectedLanguage === 'ms' ? 
            'Sambungan pelayan tidak sedia. Sila tunggu proses permulaan selesai.' :
            'Server connection not ready. Please wait for initialization to complete.';
        showToast(errorText, 'error');
        return;
    }
    
    isInConversation = true;
    
    // Change button to stop state with recording animation
    voiceBtn.classList.add('recording');
    voiceBtn.style.background = 'linear-gradient(135deg, #dc3545 0%, #c82333 100%)';
    voiceBtn.innerHTML = '<i class="fas fa-stop" style="font-size: 3rem;"></i>';
    
    const texts = {
        'en': {
            stop: 'Stop Conversation',
            starting: 'Starting voice on server...',
            toast: '🎤 Requesting server to activate voice...'
        },
        'ms': {
            stop: 'Henti Perbualan',
            starting: 'Memulakan suara di pelayan...',
            toast: '🎤 Meminta pelayan untuk mengaktifkan suara...'
        }
    };
    
    const text = texts[selectedLanguage] || texts['en'];
    voiceBtnText.textContent = text.stop;
    updateConversationState('listening', '👂', text.starting);
    updateStatus('voice', 'processing');
    
    serverWebSocket.send(JSON.stringify({
        type: 'start_voice',
        language: selectedLanguage
    }));
    
    showToast(text.toast, 'info');
}

function endConversation() {
    isInConversation = false;
    
    // Reset to original styling
    voiceBtn.classList.remove('recording');
    voiceBtn.style.background = '';
    voiceBtn.className = 'btn-primary-modern';
    voiceBtn.innerHTML = '<i class="fas fa-microphone" style="font-size: 3rem;"></i>';
    
    const texts = {
        'en': {
            start: 'Start Conversation',
            ready: 'Click the button to start',
            toast: '🔇 Requesting server to deactivate voice...'
        },
        'ms': {
            start: 'Mula Perbualan',
            ready: 'Klik butang untuk mula',
            toast: '🔇 Meminta pelayan untuk menyahaktifkan suara...'
        }
    };
    
    const text = texts[selectedLanguage] || texts['en'];
    voiceBtnText.textContent = text.start;
    updateConversationState('ready', '🤖', text.ready);
    updateStatus('voice', 'ready');
    updateStatus('ai', 'ready');
    
    if (serverWebSocket && serverWebSocket.readyState === WebSocket.OPEN) {
        serverWebSocket.send(JSON.stringify({
            type: 'stop_voice'
        }));
        showToast(text.toast, 'info');
    }
}

// Audio recording and playback functions
async function startAudioRecording() {
    try {
        updateDebugInfo('🎤 Starting audio recording...');
        
        audioStream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                sampleRate: 24000,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            }
        });
        
        const audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 24000
        });
        
        window.currentAudioContext = audioContext;
        const source = audioContext.createMediaStreamSource(audioStream);
        
        if (audioContext.audioWorklet) {
            try {
                const processorCode = `
                    class AudioProcessor extends AudioWorkletProcessor {
                        process(inputs, outputs, parameters) {
                            const input = inputs[0];
                            if (input.length > 0) {
                                const channelData = input[0];
                                const pcm16 = new Int16Array(channelData.length);
                                for (let i = 0; i < channelData.length; i++) {
                                    pcm16[i] = Math.max(-32768, Math.min(32767, channelData[i] * 32768));
                                }
                                this.port.postMessage({
                                    type: 'audio_data',
                                    data: pcm16.buffer
                                });
                            }
                            return true;
                        }
                    }
                    registerProcessor('audio-processor', AudioProcessor);
                `;
                
                const blob = new Blob([processorCode], { type: 'application/javascript' });
                const processorUrl = URL.createObjectURL(blob);
                
                await audioContext.audioWorklet.addModule(processorUrl);
                const processorNode = new AudioWorkletNode(audioContext, 'audio-processor');
                
                processorNode.port.onmessage = (event) => {
                    if (event.data.type === 'audio_data' && serverWebSocket && serverWebSocket.readyState === WebSocket.OPEN) {
                        const uint8Array = new Uint8Array(event.data.data);
                        let binaryString = '';
                        for (let i = 0; i < uint8Array.byteLength; i++) {
                            binaryString += String.fromCharCode(uint8Array[i]);
                        }
                        const base64Audio = btoa(binaryString);
                        
                        serverWebSocket.send(JSON.stringify({
                            type: 'audio_data',
                            audio: base64Audio
                        }));
                    }
                };
                
                source.connect(processorNode);
                processorNode.connect(audioContext.destination);
                
                updateDebugInfo('✅ Using AudioWorklet for audio processing');
                
            } catch (error) {
                updateDebugInfo(`❌ AudioWorklet failed: ${error.message}, falling back to ScriptProcessor`);
                useScriptProcessor();
            }
        } else {
            updateDebugInfo('⚠️ AudioWorklet not supported, using ScriptProcessor');
            useScriptProcessor();
        }
        
        function useScriptProcessor() {
            const processor = audioContext.createScriptProcessor(4096, 1, 1);
            
            processor.onaudioprocess = function(e) {
                if (serverWebSocket && serverWebSocket.readyState === WebSocket.OPEN) {
                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }
                    
                    const uint8Array = new Uint8Array(pcm16.buffer);
                    let binaryString = '';
                    for (let i = 0; i < uint8Array.byteLength; i++) {
                        binaryString += String.fromCharCode(uint8Array[i]);
                    }
                    const base64Audio = btoa(binaryString);
                    
                    serverWebSocket.send(JSON.stringify({
                        type: 'audio_data',
                        audio: base64Audio
                    }));
                }
            };
            
            source.connect(processor);
            processor.connect(audioContext.destination);
        }
        
        updateDebugInfo('✅ Audio recording started');
        updateStatus('voice', 'listening');
        updateConversationState('listening', '👂', 'Listening...');
        
    } catch (error) {
        updateDebugInfo(`❌ Failed to start audio recording: ${error.message}`);
        showToast(`Microphone Error: ${error.message}`, 'error');
    }
}

function stopAudioRecording() {
    try {
        updateDebugInfo('🛑 Stopping audio recording...');
        
        if (audioStream) {
            audioStream.getTracks().forEach(track => track.stop());
            audioStream = null;
        }
        
        if (window.currentAudioContext) {
            window.currentAudioContext.close();
            window.currentAudioContext = null;
        }
        
        updateStatus('voice', 'ready');
        updateConversationState('ready', '🤖', 'Click the button to start');
        updateDebugInfo('✅ Audio recording stopped');
        
    } catch (error) {
        updateDebugInfo(`❌ Error stopping audio recording: ${error.message}`);
    }
}

// Audio playback setup
if (!audioEl) {
    audioEl = document.createElement("audio");
    audioEl.autoplay = true;
    document.body.appendChild(audioEl);
    updateDebugInfo('🔊 Audio element created for playback');
}

// Audio buffer management
let globalAudioContext = null;
let audioChunksBuffer = [];
let isBuffering = false;
let nextPlayTime = 0;

async function playAudioDelta(audioData) {
    try {
        if (!audioData) return;
        
        if (isBuffering) {
            audioChunksBuffer.push(audioData);
            updateDebugInfo(`📦 Buffering audio chunk - Buffer size: ${audioChunksBuffer.length}`);
        } else {
            await playAudioChunk(audioData);
        }
        
    } catch (error) {
        updateDebugInfo(`❌ Error handling audio: ${error.message}`);
    }
}

async function playAudioChunk(audioData) {
    try {
        if (!globalAudioContext) {
            globalAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 24000
            });
            
            if (globalAudioContext.state === 'suspended') {
                await globalAudioContext.resume();
                updateDebugInfo('🔊 Audio context resumed');
            }
            
            nextPlayTime = globalAudioContext.currentTime;
        }
        
        const binaryString = atob(audioData);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        
        const pcm16Array = new Int16Array(bytes.buffer);
        
        if (pcm16Array.length > 0) {
            const audioBuffer = globalAudioContext.createBuffer(1, pcm16Array.length, 24000);
            const channelData = audioBuffer.getChannelData(0);
            
            for (let i = 0; i < pcm16Array.length; i++) {
                channelData[i] = pcm16Array[i] / 32768;
            }
            
            const source = globalAudioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(globalAudioContext.destination);
            
            const startTime = Math.max(nextPlayTime, globalAudioContext.currentTime);
            source.start(startTime);
            
            nextPlayTime = startTime + audioBuffer.duration;
            
            updateDebugInfo(`▶️ Audio chunk scheduled at ${startTime.toFixed(3)}s`);
        }
        
    } catch (error) {
        updateDebugInfo(`❌ Error playing audio chunk: ${error.message}`);
    }
}

async function startAudioBuffer() {
    updateDebugInfo('🎬 Starting audio buffer collection');
    audioChunksBuffer = [];
    isBuffering = true;
    updateStatus('ai', 'speaking');
    updateConversationState('speaking', '🗣️', 'AI Speaking...');
}

async function completeAudioBuffer() {
    updateDebugInfo(`🎯 Completing audio buffer - Playing ${audioChunksBuffer.length} chunks`);
    isBuffering = false;
    
    for (const chunk of audioChunksBuffer) {
        await playAudioChunk(chunk);
    }
    
    audioChunksBuffer = [];
    
    updateDebugInfo('✅ Audio buffer playback completed');
    updateStatus('ai', 'ready');
    updateConversationState('listening', '👂', 'Listening...');
}

function clearAudioQueue() {
    audioChunksBuffer = [];
    isBuffering = false;
    nextPlayTime = 0;
    
    if (globalAudioContext) {
        try {
            globalAudioContext.close();
            globalAudioContext = null;
            updateDebugInfo('🔇 Audio context closed');
        } catch (error) {
            updateDebugInfo(`⚠️ Error closing audio context: ${error.message}`);
        }
    }
    updateStatus('ai', 'ready');
    updateConversationState('listening', '👂', 'Listening...');
}

function updateTranscriptionPreview(speaker, text, isComplete = false) {
    if (!text) return;
    
    transcriptionPreview.classList.remove('d-none');
    transcriptionPreview.classList.add('fade-in');
    previewIcon.textContent = speaker === 'user' ? '👤' : '🤖';
    previewText.textContent = text;
    
    if (isComplete) {
        typingIndicator.style.display = 'none';
        setTimeout(clearTranscriptionPreview, 2000);
    } else {
        typingIndicator.style.display = 'inline';
        animateTypingIndicator();
    }
}

function clearTranscriptionPreview() {
    transcriptionPreview.classList.add('d-none');
    transcriptionPreview.classList.remove('fade-in');
    previewText.textContent = '';
    typingIndicator.style.display = 'none';
}

function animateTypingIndicator() {
    const chars = ['▋', '▊', '▉', '█', '▉', '▊'];
    let index = 0;
    
    const animate = () => {
        if (transcriptionPreview.classList.contains('d-none')) return;
        
        typingIndicator.textContent = chars[index];
        index = (index + 1) % chars.length;
        setTimeout(animate, 300);
    };
    
    animate();
}

function updateConversationState(state, icon, text) {
    conversationState.className = `alert alert-${getAlertClass(state)}`;
    stateIndicator.textContent = icon;
    stateText.textContent = text;
}

function getAlertClass(state) {
    switch (state) {
        case 'listening': return 'success';
        case 'processing': return 'warning';
        case 'speaking': return 'info';
        case 'error': return 'danger';
        default: return 'secondary';
    }
}

function clearConversation() {
    const welcomeMessage = conversationMessages.querySelector('.message.assistant');
    conversationMessages.innerHTML = '';
    if (welcomeMessage) {
        conversationMessages.appendChild(welcomeMessage);
    }
    updateDebugInfo('🧹 Conversation history cleared');
}

function showToast(message, type = 'info') {
    const toast = document.getElementById('notification-toast');
    const toastMessage = document.getElementById('toast-message');
    
    toastMessage.textContent = message;
    toast.className = `toast ${type === 'error' ? 'bg-danger text-white' : 'bg-success text-white'}`;
    
    const bsToast = new bootstrap.Toast(toast);
    bsToast.show();
}

function getCookie(name) {
    let cookieValue = null;
    if (document.cookie && document.cookie !== '') {
        const cookies = document.cookie.split(';');
        for (let i = 0; i < cookies.length; i++) {
            const cookie = cookies[i].trim();
            if (cookie.substring(0, name.length + 1) === (name + '=')) {
                cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                break;
            }
        }
    }
    return cookieValue;
}
</script>
{% endblock %}