{% extends 'base.html' %}

{% block title %}Voice Test{% endblock %}

{% block content %}
<div class="container-fluid py-4">
    <div class="row">
        <div class="col-md-8 mx-auto">
            <div class="card shadow-lg">
                <div class="card-header bg-primary text-white">
                    <h4 class="mb-0">
                        <i class="fas fa-microphone me-2"></i>
                        Voice Assistant Test
                    </h4>
                    <small>STT → LLM → TTS Pipeline Testing</small>
                </div>
                <div class="card-body">
                    <!-- Assistant Info -->
                    <div class="alert alert-info">
                        <strong>Assistant:</strong> {{ assistant.business_type.name }} Customer Service<br>
                        <strong>Knowledge Base Items:</strong> {{ assistant.knowledge_base.count }}<br>
                        <strong>Q&A Items:</strong> {{ assistant.qnas.count }}
                    </div>

                    <!-- Voice Controls -->
                    <div class="row mb-4">
                        <div class="col-md-6">
                            <div class="card h-100">
                                <div class="card-header bg-success text-white">
                                    <h6 class="mb-0">Push to Talk</h6>
                                </div>
                                <div class="card-body text-center">
                                    <button id="recordBtn" class="btn btn-success btn-lg rounded-circle" 
                                            style="width: 80px; height: 80px;" 
                                            onmousedown="startRecording()" 
                                            onmouseup="stopRecording()"
                                            onmouseleave="stopRecording()">
                                        <i class="fas fa-microphone fa-2x"></i>
                                    </button>
                                    <p class="mt-3 mb-0">
                                        <small class="text-muted">Hold to record</small>
                                    </p>
                                    <div id="recordingStatus" class="mt-2"></div>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-6">
                            <div class="card h-100">
                                <div class="card-header bg-info text-white">
                                    <h6 class="mb-0">Audio Playback</h6>
                                </div>
                                <div class="card-body">
                                    <audio id="audioPlayer" controls class="w-100 mb-3" style="display: none;">
                                        Your browser does not support the audio element.
                                    </audio>
                                    <button id="playLastBtn" class="btn btn-info w-100" disabled onclick="playLastResponse()">
                                        <i class="fas fa-play me-2"></i>Play Last Response
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Pipeline Status -->
                    <div class="card mb-4">
                        <div class="card-header">
                            <h6 class="mb-0">Pipeline Status</h6>
                        </div>
                        <div class="card-body">
                            <div class="row">
                                <div class="col-md-4">
                                    <div class="text-center">
                                        <div id="sttStatus" class="status-indicator mb-2">
                                            <i class="fas fa-microphone-alt fa-2x text-muted"></i>
                                        </div>
                                        <h6>Speech to Text</h6>
                                        <small class="text-muted">OpenAI Whisper</small>
                                    </div>
                                </div>
                                <div class="col-md-4">
                                    <div class="text-center">
                                        <div id="llmStatus" class="status-indicator mb-2">
                                            <i class="fas fa-brain fa-2x text-muted"></i>
                                        </div>
                                        <h6>Language Model</h6>
                                        <small class="text-muted">GPT-4o-mini + RAG</small>
                                    </div>
                                </div>
                                <div class="col-md-4">
                                    <div class="text-center">
                                        <div id="ttsStatus" class="status-indicator mb-2">
                                            <i class="fas fa-volume-up fa-2x text-muted"></i>
                                        </div>
                                        <h6>Text to Speech</h6>
                                        <small class="text-muted">OpenAI TTS</small>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Conversation History -->
                    <div class="card">
                        <div class="card-header d-flex justify-content-between align-items-center">
                            <h6 class="mb-0">Conversation History</h6>
                            <button class="btn btn-sm btn-outline-secondary" onclick="clearHistory()">
                                <i class="fas fa-trash me-1"></i>Clear
                            </button>
                        </div>
                        <div class="card-body" style="max-height: 400px; overflow-y: auto;">
                            <div id="conversationHistory">
                                <div class="alert alert-light text-center">
                                    <i class="fas fa-comments fa-2x text-muted mb-2"></i><br>
                                    Start a voice conversation by holding the microphone button
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<style>
.status-indicator {
    transition: all 0.3s ease;
}

.status-indicator.processing {
    animation: pulse 1s infinite;
}

.status-indicator.success {
    color: #28a745 !important;
}

.status-indicator.error {
    color: #dc3545 !important;
}

@keyframes pulse {
    0% { transform: scale(1); }
    50% { transform: scale(1.1); }
    100% { transform: scale(1); }
}

#recordBtn.recording {
    background-color: #dc3545 !important;
    border-color: #dc3545 !important;
    animation: recordPulse 1s infinite;
}

@keyframes recordPulse {
    0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7); }
    70% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(220, 53, 69, 0); }
    100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(220, 53, 69, 0); }
}

.message-item {
    margin-bottom: 15px;
    padding: 15px;
    border-radius: 10px;
    border-left: 4px solid;
}

.message-item.user {
    background-color: #e3f2fd;
    border-left-color: #2196f3;
}

.message-item.assistant {
    background-color: #f3e5f5;
    border-left-color: #9c27b0;
}

.transcript-text {
    font-style: italic;
    color: #666;
    font-size: 0.9em;
}

.response-text {
    margin-top: 8px;
}
</style>

<script>
let mediaRecorder = null;
let isRecording = false;
let sessionId = null;
let lastAudioResponse = null;

// Initialize
document.addEventListener('DOMContentLoaded', function() {
    // Check for microphone permissions
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        console.log('Media devices API supported');
    } else {
        alert('Media devices API not supported in this browser');
    }
});

async function startRecording() {
    if (isRecording) return;
    
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                sampleRate: 16000,
                channelCount: 1,
                volume: 1.0
            }
        });
        
        const recordBtn = document.getElementById('recordBtn');
        const recordingStatus = document.getElementById('recordingStatus');
        
        recordBtn.classList.add('recording');
        recordingStatus.innerHTML = '<span class="text-danger"><i class="fas fa-circle"></i> Recording...</span>';
        
        // Reset pipeline status
        resetPipelineStatus();
        
        mediaRecorder = new MediaRecorder(stream, {
            mimeType: 'audio/webm;codecs=opus'
        });
        
        const audioChunks = [];
        
        mediaRecorder.ondataavailable = event => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            await processVoiceMessage(audioBlob);
            
            // Stop all tracks
            stream.getTracks().forEach(track => track.stop());
        };
        
        mediaRecorder.start();
        isRecording = true;
        
    } catch (error) {
        console.error('Error starting recording:', error);
        alert('Microphone access denied or not available. Please check your browser permissions.');
    }
}

function stopRecording() {
    if (!isRecording || !mediaRecorder) return;
    
    const recordBtn = document.getElementById('recordBtn');
    const recordingStatus = document.getElementById('recordingStatus');
    
    recordBtn.classList.remove('recording');
    recordingStatus.innerHTML = '<span class="text-warning"><i class="fas fa-spinner fa-spin"></i> Processing...</span>';
    
    mediaRecorder.stop();
    isRecording = false;
}

async function processVoiceMessage(audioBlob) {
    const recordingStatus = document.getElementById('recordingStatus');
    
    try {
        // Step 1: STT
        updatePipelineStatus('stt', 'processing');
        recordingStatus.innerHTML = '<span class="text-info"><i class="fas fa-microphone-alt"></i> Converting speech to text...</span>';
        
        const formData = new FormData();
        formData.append('audio', audioBlob, 'voice.webm');
        formData.append('session_id', sessionId || '');
        
        const response = await fetch('/api/voice-test/', {
            method: 'POST',
            body: formData,
            headers: {
                'X-CSRFToken': getCookie('csrftoken')
            }
        });
        
        const data = await response.json();
        
        if (data.status === 'success') {
            updatePipelineStatus('stt', 'success');
            updatePipelineStatus('llm', 'success');
            updatePipelineStatus('tts', 'success');
            
            sessionId = data.session_id;
            
            // Add conversation to history
            addConversationItem(data.transcribed_text, 'user', true); // This is what user said (transcribed)
            addConversationItem(data.text_response, 'assistant', false); // This is assistant response
            
            // Handle audio response
            if (data.audio_response) {
                const audioData = base64ToBlob(data.audio_response, 'audio/mp3');
                const audioUrl = URL.createObjectURL(audioData);
                lastAudioResponse = audioUrl;
                
                // Auto-play the response
                playAudio(audioUrl);
                
                // Enable play button
                document.getElementById('playLastBtn').disabled = false;
            }
            
            recordingStatus.innerHTML = '<span class="text-success"><i class="fas fa-check"></i> Completed!</span>';
            
            setTimeout(() => {
                recordingStatus.innerHTML = '';
            }, 3000);
            
        } else {
            updatePipelineStatus('stt', 'error');
            recordingStatus.innerHTML = '<span class="text-danger"><i class="fas fa-exclamation-triangle"></i> Error: ' + (data.error || 'Unknown error') + '</span>';
            
            // Log detailed error for debugging
            console.error('Voice API Error:', data);
        }
        
    } catch (error) {
        console.error('Error processing voice message:', error);
        updatePipelineStatus('stt', 'error');
        recordingStatus.innerHTML = '<span class="text-danger"><i class="fas fa-exclamation-triangle"></i> Network error: ' + error.message + '</span>';
        
        // Show error in conversation history too
        addConversationItem('Error: Failed to process voice message. Please try again.', 'assistant', false);
    }
}

function addConversationItem(text, type, isTranscript = false) {
    const history = document.getElementById('conversationHistory');
    
    // Clear welcome message if it exists
    if (history.querySelector('.alert-light')) {
        history.innerHTML = '';
    }
    
    const messageDiv = document.createElement('div');
    messageDiv.className = `message-item ${type}`;
    
    const timestamp = new Date().toLocaleTimeString();
    const icon = type === 'user' ? 'fas fa-user' : 'fas fa-robot';
    const label = type === 'user' ? 'You' : 'Assistant';
    
    let content = '';
    if (isTranscript) {
        content = `
            <div class="d-flex justify-content-between align-items-center mb-2">
                <strong><i class="${icon} me-2"></i>${label}</strong>
                <small class="text-muted">${timestamp}</small>
            </div>
            <div class="transcript-text">
                <i class="fas fa-microphone-alt me-1"></i>Transcribed: "${text}"
            </div>
        `;
    } else {
        content = `
            <div class="d-flex justify-content-between align-items-center mb-2">
                <strong><i class="${icon} me-2"></i>${label}</strong>
                <small class="text-muted">${timestamp}</small>
            </div>
            <div class="response-text">${text}</div>
        `;
    }
    
    messageDiv.innerHTML = content;
    history.appendChild(messageDiv);
    
    // Scroll to bottom
    history.scrollTop = history.scrollHeight;
}

function updatePipelineStatus(step, status) {
    const element = document.getElementById(`${step}Status`);
    const icon = element.querySelector('i');
    
    // Reset classes
    element.className = 'status-indicator mb-2';
    icon.className = icon.className.split(' ')[0] + ' fa-2x';
    
    switch (status) {
        case 'processing':
            element.classList.add('processing');
            icon.classList.add('text-warning');
            break;
        case 'success':
            element.classList.add('success');
            icon.classList.add('text-success');
            break;
        case 'error':
            element.classList.add('error');
            icon.classList.add('text-danger');
            break;
        default:
            icon.classList.add('text-muted');
    }
}

function resetPipelineStatus() {
    ['stt', 'llm', 'tts'].forEach(step => {
        updatePipelineStatus(step, 'default');
    });
}

function playLastResponse() {
    if (lastAudioResponse) {
        playAudio(lastAudioResponse);
    }
}

function playAudio(audioUrl) {
    const audioPlayer = document.getElementById('audioPlayer');
    audioPlayer.src = audioUrl;
    audioPlayer.style.display = 'block';
    audioPlayer.play();
}

function clearHistory() {
    const history = document.getElementById('conversationHistory');
    history.innerHTML = `
        <div class="alert alert-light text-center">
            <i class="fas fa-comments fa-2x text-muted mb-2"></i><br>
            Start a voice conversation by holding the microphone button
        </div>
    `;
    sessionId = null;
    lastAudioResponse = null;
    document.getElementById('playLastBtn').disabled = true;
    document.getElementById('audioPlayer').style.display = 'none';
}

function base64ToBlob(base64, contentType) {
    const byteCharacters = atob(base64);
    const byteNumbers = new Array(byteCharacters.length);
    for (let i = 0; i < byteCharacters.length; i++) {
        byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: contentType });
}

function getCookie(name) {
    let cookieValue = null;
    if (document.cookie && document.cookie !== '') {
        const cookies = document.cookie.split(';');
        for (let i = 0; i < cookies.length; i++) {
            const cookie = cookies[i].trim();
            if (cookie.substring(0, name.length + 1) === (name + '=')) {
                cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                break;
            }
        }
    }
    return cookieValue;
}

// Prevent context menu on record button to avoid interference
document.getElementById('recordBtn').addEventListener('contextmenu', function(e) {
    e.preventDefault();
});
</script>
{% endblock %}